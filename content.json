{"pages":[{"title":"about","text":"找工作 ing","link":"/about/index.html"},{"title":"简历","text":"个人信息姓名：李超生日：1993-04-13籍贯：湖南-郴州学校：中国计量学院专业：机械电子工程学历：本科 联系方式手机：15658109965邮箱：relengxing@outlook.comQQ：670656469微信：15658109965 我的技能 精通 Java，熟悉 SpringBoot、Spring、SpringMVC、Mybatis 等开发框架,熟悉微服务，熟悉 SpringCloud，了解 Istio 熟悉 Python，熟悉 Pandas，PySprk，主要是数据处理方向 熟悉 JS、HTML、CSS、jQuery、Bootstrap 等前端知识 熟悉 MySQL，Redis，Mongodb，RabbitMQ 熟悉 Linux能完成生产环境搭建及服务器运维 熟悉 Docker、Kubernetes经历公司容器化发展，能进行容器化开发和运维 熟悉云服务Azure：熟悉 Databricks（Spark）、DataLake(Hdfs)等工具Google Cloud：DataProc（Spark）、BigQuery(Hdfs)等工具经历公司从 Azure 迁移到 Google Cloud 熟悉 C 语言和 Go 语言 工作经验 公司：贝深科技（深圳）有限公司职务：Java 开发工程师时间： 2017.02-至今Percolata 是一家利用大数据和 Machine Learning 技术为零售商提供综合数据与分析的美企。服务器在 Azure 和 Google Cloud。加入公司的时候是公司人员大换血时，第一年只有我一个 Java 后端，工作内容包括修复线上 Bug，开发新需求，服务器运维。开发了一个新项目的后端，项目是基于 SpringBoot 开发的。第二年开始主要是新版本的开发，项目是基于 SpringCloud 开发的。后来公司转型，应用端放弃维护，开始转到 Python 开发，主要是数据处理方向。技术栈包括 Python、Pandas、云平台的 Spark 及 Hadoop 等。期间对 Kubernetes 研究较多，完成了公司项目容器化，统一了数据处理流程，开发了一个 Kubernetes 任务发布系统。 公司：杭州能联科技有限公司职务：嵌入式软件开发工程师时间： 2014.12-2016.08公司的主营业务是智能水表和远程集抄。在公司期间完成了多个项目和模块开发，如 GPRS 单表主动上报式采集器，无磁水表，蓝牙转串口模块等，能快速学习使用一个新的单片机，能自己研究手册独立进行开发。 教育背景 学校：中国计量学院 专业：机械电子工程 时间：2011.09 - 2015.06 学历：本科 个人介绍 五年软件开发经验，三年 Java 开发经验，基础扎实，涉猎广泛。 学习能力强，能快速上手新技术，具备主动学习精神。 思路清晰，具有良好的方案设计能力，解决问题能力强。 沟通能力强，具有良好的团队合作精神。 社交主页 博客：https://relengxing.github.io/ Github：https://github.com/relengxing 简书：http://www.jianshu.com/u/d7acd6530ab6 项目经验 项目名称: ETL pipeline时间：2019.01 – 2019.10负责内容：Python 软件开发项目介绍：此项目包含多个模块，流程是：客户上传文件到 FTP 服务器或者 Google Drive,触发器会根据配置扫描 FTP 服务器和 Google Drive，如果有符合规则的文件则进过简单的处理后上传到 Google Storage,并触发 Data Proc 任务，Data Proc 会对数据去重并写入 Big Query，然后预处理模块会对数据进行处理，检查出异常数据和缺失数据，并对数据进行修复，写入到 Big Query 中，这部分数据会供预测算法使用，最后还会提取数据，写入到数据仓库中，方便报告使用。 项目名称：Kuberobot时间：2018.11 – 2018.12负责内容：Java 软件开发项目介绍：此项目是一个 Kubernetes 任务发布系统，公司的任务统一发布到 redis，kuberobot 会根据任务优先级把任务发布到 kubernetes，并发送运行结果到 Slack 上，会根据任务队列的长度对 Kubernetes 进行扩缩容，支持自动扩容和手动扩容。 项目名称：Admin portal时间：2017.08 – 2019.09负责内容：Java 软件开发项目介绍：此项目是一个对客户店铺和设备进行管理的项目，提供数据展示（例如：设备存活率，历史 data hole 等），设备配置，数据导入等功能，后端使用的是 SpringBoot，前端使用的是 JQuery，Bootstrap。 项目名称：Staffum时间：2017.02 – 2018.10负责内容：Java 软件开发项目介绍：此项目是我加入 Percolata 接手的项目，主要是对零售商的数据进行管理（店铺数据，员工数据，销售数据，人流量数据），提供数据展示，排班（手动排班和自动排班），请假等功能。我负责的是整个项目的维护，新需求开发，新版本开发。第一个版本后端使用 Springboot,管理员前端使用的是 angular，员工前端使用的是 React Native，第二个版本后端使用的是 SpringCloud，前端使用的是 ionic。 项目名称：模拟采集器和主站时间：2017.01 – 2017.01负责内容：JAVA 软件开发，Golang 软件开发项目介绍：此项目分为两部分：集中器部分和主站部分。集中器是使用 Golang 开发的模拟集中器，可以使用网页对模拟集中器进行管理，程序会定启动，上报数据到主站。主站是使用 JAVA 开发的服务器，可以使用网页对表记信息和表记数据进行管理。 项目名称：单表主动上报式采集器时间：2015.12 – 2016.02负责内容：单片机软件开发项目介绍：此项目是使用 EFM32TG840 单片机对水表进行数据采集。定期通过 GPRS M6310 模块与主站通讯，上报抄表数据，参数可以通过主站或者本地操控器进行设置。 项目名称：无磁水表时间：2015.03 – 2015.06负责内容：单片机软件开发，上位机软件开发（C#）项目介绍：此项目是基于 msp430fw427 单片机开发的。该项目主要是通过 ScanIF 模块和 LC 振荡电路来对水表转子的转动进行计数。并可以通过上位机的小软件对单片机进行数据采集和阀门控制。上位机的软件是用 C#开发的 项目名称：蓝牙转串口模块时间：2015.01 – 2015.01负责内容：单片机软件开发项目介绍：此项目是基于 SCH16L 单片机和 HC-06 蓝牙模块开发的。单片机通过一个串口和蓝牙模块进行通讯，另一个串口连接表记。可以通过给蓝牙发送数据和另一端的表记进行通讯。单片机可以识别是数据还是命令码，命令码可以对波特率等参数进行修改。 项目名称：爬壁机器人时间：2013.10 – 2014.05负责内容：Solidworks 三维制图，电机驱动开发项目介绍：这是一个大学时做的项目，是可以在垂直墙面上运动的机器人，该项目还参与了挑战杯，获得挑战杯校一等奖。我是机械部分的负责人，负责机械部分设计，三维制图，并参与了电机驱动部分的软件开发。","link":"/cv/index.html"}],"posts":[{"title":"ReBus","text":"说明ReBus 是一个模仿 RxBus 写的，基于 reactor3 的事件总线 RxBus 一般是 Android 端使用的，ReBus 一般是后端使用的RxBus 参考链接： https://github.com/relengxing/RxBusReBus 源码链接： https://github.com/relengxing/ReBus 推荐直接看 RxBus 的解析，这边只贴代码，因为思想是一模一样的，只是底层的包不一样，封装完后用法也是一样的。 源码解析ReBus 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.relenxing.config;import com.relenxing.domain.Event;import reactor.core.publisher.Flux;import reactor.core.publisher.ReplayProcessor;public class ReBus { /** * 事件总线的核心。 */ private final ReplayProcessor&lt;Event&gt; bus; /** * 构造函数，初始化 */ private ReBus() { bus = ReplayProcessor.create(); } /** * 单例模式 */ public static ReBus getDefault() { return HelperHolder.instance; } /** * 延迟初始化，这里是利用了 Java 的语言特性，内部类只有在使用的时候，才会去加载， * 从而初始化内部静态变量。关于线程安全，这是 Java 运行环境自动给你保证的， * 在加载的时候，会自动隐形的同步。在访问对象的时候， * 不需要同步 Java 虚拟机又会自动给你取消同步，所以效率非常高。 */ private static class HelperHolder { static final ReBus instance = new ReBus(); } /** * 发送普通事件 */ public void post(Event event){ bus.onNext(event); } public Flux&lt;Event&gt; on(String type){ return bus.filter(e -&gt; e.getEventName().equals(type)); }} Event 代码： 12345678910111213141516171819202122232425262728293031323334353637package com.relenxing.domain;import java.io.Serializable;public class Event&lt;T&gt; implements Serializable { private static final long serialVersionUID = 1L; private String eventName; private T event; public Event() { } public Event(String eventName, T event) { this.eventName = eventName; this.event = event; } public String getEventName() { return eventName; } public void setEventName(String eventName) { this.eventName = eventName; } public T getEvent() { return event; } public void setEvent(T event) { this.event = event; }} demo 1234567891011121314package com.relenxing;public class Main { public static void main(String[] args) { ReBus.getDefault().post(new Event&lt;&gt;(&quot;123&quot;, &quot;123&quot;)); ReBus.getDefault().post(new Event&lt;&gt;(&quot;456&quot;, &quot;swdw&quot;)); ReBus.getDefault().post(new Event&lt;&gt;(&quot;123&quot;, &quot;312&quot;)); ReBus.getDefault().post(new Event&lt;&gt;(&quot;456&quot;, &quot;2f2&quot;)); ReBus.getDefault().post(new Event&lt;&gt;(&quot;123&quot;, &quot;12f&quot;)); ReBus.getDefault().on(&quot;123&quot;).map(Event::getEvent).subscribe(System.out::println); ReBus.getDefault().on(&quot;456&quot;).map(Event::getEvent).subscribe(System.out::println); }}","link":"/2017/09/08/ReBus/"},{"title":"RxBus","text":"参考：用 RxJava 实现事件总线(Event Bus)http://www.jianshu.com/p/ca090f6e2fe2 我这篇基本上就是按照上面那篇写的，对 Sticky 那一块进行了一些修改。写下来让自己记得更深刻。这篇文章面向有 RxJava 基础的人，要是 HelloWorld 都没写过建议先看基础部分。 Git 地址：https://github.com/relengxing/RxBus 步骤 新建工程 添加 rxjava 和 rxandroid 依赖 完成以下界面 编写 RxBus 文件 编写其他代码 RxBus 是一个全局使用的总线，应该使用单例模式。单例模式的具体写法可以自己研究下。参考代码：http://www.race604.com/java-double-checked-singleton/ 1234567891011121314/*** Created by relengxing on 2016/8/12.*/public class RxBus { private RxBus() { } public static RxBus getDefault() { return HelperHolder.instance; } private static class HelperHolder { public static final RxBus instance = new RxBus(); }} 事件总线那么需要一根总线来传输数据。这根总线就是 RxJava 中的 Subject。 Subject 可以看成是一个桥梁或者代理，在某些 ReactiveX 实现中（ 如 RxJava） ，它同时充当了 Observer 和 Observable 的角色。因为它是一个 Observer，它可以订阅一个或多个 Observable；又因为它是一个 Observable，它可以转发它收到(Observe)的数据，也可以发射新的数据。 在 RxJava 中针对不同的场景一共有四种类型的 Subject。 AsyncSubject BehaviorSubject PublishSubject ReplaySubject关于这四种类型的具体说明参考：RxJava：Subject 介绍 这里使用的是 PublishSubjectPublishSubject：只会把在订阅发生的时间点之后来自原始 Observable 的数据发射给观察者；又因为线程安全的问题，需要把 PublishSubject 转化为一个线程安全的 Subject，这部分内容也在RxJava：Subject 介绍最后一部分串行化中有介绍。最后代码写成如下： private final Subject&lt;Object,Object&gt; bus; private RxBus() { bus = new SerializedSubject&lt;&gt;(PublishSubject.create()); }总线有了，还差事件发布者（被观察者）和事件接受者（观察者）。 发送事件将事件 post 至 Subject，此时 Subject 作为 Observer 接收到事件（onNext），然后会发射给所有订阅该 Subject 的订阅者。因为使用的是 PublishSubject，所以必须先订阅事件再发送事件才能介绍到，否则这些发送的事件会遗失。 123public void post(Object object){ bus.onNext(object);} 接收事件123public &lt;T&gt; Observable&lt;T&gt; toObservable(Class&lt;T&gt; eventType){ return bus.ofType(eventType);} ofType 是 filter 操作符的一个特殊形式。它过滤一个 Observable 只返回指定类型的数据。ofType 默认不在任何特定的调度器上指定 。 有一点需要注意的是，在接收事件的地方不需要接收事件或者生命周期结束的时候一定要取消订阅，防止内存泄漏。 123if (!rxSubscription2.isUnsubscribed()) { rxSubscription2.unsubscribe();} 支持 Sticky 事件 在 Android 开发中，Sticky 事件只指事件消费者在事件发布之后才注册的也能接收到该事件的特殊类型。Android 中就有这样的实例，也就是 Sticky Broadcast，即粘性广播。正常情况下如果发送者发送了某个广播，而接收者在这个广播发送后才注册自己的 Receiver，这时接收者便无法接收到刚才的广播，为此 Android 引入了 StickyBroadcast，在广播发送结束后会保存刚刚发送的广播（Intent），这样当接收者注册完 Receiver 后就可以接收到刚才已经发布的广播。这就使得我们可以预先处理一些事件，让有消费者时再把这些事件投递给消费者。 参考：深入 RxBus：［支持 Sticky 事件］ 关于方案选择不再详述了，参考上面的链接。同样使用的是 ConcurrentHashMap参考资料中使用的是 1private final Map&lt;Class&lt;?&gt;, Object&gt; mStickyEventMap; 那么同一个类只会有一个对象保留，后面发送的对象会把前面的对象覆盖掉。而我希望一个新的对象不会覆盖老的对象，需要自己手动来删除。所以这个地方改成 1private final ConcurrentHashMap&lt;Class&lt;?&gt;,List&lt;Object&gt;&gt; map; Sticky 事件和普通事件使用的是同一个 Bus,所以接收者接收的是同一个对象时，当他们都订阅了事件时是没有区别的。 发送 Sticky 事件这个其实就是在发送普通时间之前把这个事件写入到刚刚的 map 中去。 1234567891011public void postSticky(Object object){ synchronized (mStickyEventMap){ List list = mStickyEventMap.get(object.getClass()); if (list == null) { list = new ArrayList(); } list.add(object); mStickyEventMap.put(object.getClass(),list); } post(object);} 接收 Sticky 事件这个就是先查看 map 中是否有这个事件，有的话使用.merginWith 一起发出来。 123456789101112131415161718public &lt;T&gt; Observable&lt;T&gt; toObservableSticky(final Class&lt;T&gt; eventType){ synchronized (mStickyEventMap){ Observable&lt;T&gt; observable = bus.ofType(eventType); final List list = mStickyEventMap.get(eventType); if (list != null &amp;&amp; !list.isEmpty()) { return observable.mergeWith(Observable.create(new Observable.OnSubscribe&lt;T&gt;(){ @Override public void call(Subscriber&lt;? super T&gt; subscriber) { for (Object obj :list) { subscriber.onNext(eventType.cast(obj)); } } })); }else { return observable; } }} 还写了一些常用方法，例如 post 一个事件的时候覆盖同类事件，接收事件时消耗掉事件，代码在简书上写起来还是有点麻烦，详情看 GitHub，地址：https://github.com/relengxing/RxBus要使用的时候把 RxBus 文件直接复制到工程即可。如果有 BUG 可以在评论区告诉我。","link":"/2016/08/13/RxBus/"},{"title":"keepalive_docker_nginx实践","text":"我的本地环境，一台 Unbuntu 18.04 系统的物理机想实践下 虚拟 ip，keepalive就一台机器，所以用 docker 来实践一下。 关于虚拟 ip, 可以看下这篇文章https://www.gitos.org/2019/08/19/vip-ha.html 关于 docker, keepalive 基本按这篇文章https://www.jianshu.com/p/6a8f38b8076d 修改 dockerfile，减少重复下载环境 12345678FROM centos:latestMAINTAINER relengxing&lt;relengxing@outlook.com&gt;RUN yum install -y gcc openssl-devel popt-develRUN yum install -y net-toolsRUN yum install -y vimRUN yum install -y keepalivedRUN yum install -y nginx 启动 centos 容器–privileged=true 获取特权/sbin/init：这个地方是实测 /bin/bash，会有权限没有。因为我还实验了下手动加虚拟 ip 12docker run --name centos_master -itd --privileged=true relengxing/centos:v1 /sbin/initdocker run --name centos_slave -itd --privileged=true relengxing/centos:v1 /sbin/init 可以进容器查看 ip 地址 Master 节点ifconfig 123eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500inet 172.17.0.3 netmask 255.255.0.0 broadcast 172.17.255.255ether 02:42:ac:11:00:03 txqueuelen 0 (Ethernet) 在容器外则通过 docker networkdocker network lsdocker network inspect d8c58097a4c3 ifconfig eth0:0 172.17.0.88 netmask 255.255.0.0 upifconfig eth0:0 down 修改/etc/keepalived/keepalived.conf的内容 主节点 1234567891011121314151617181920212223242526272829303132333435363738! Configuration File for keepalivedglobal_defs { notification_email { xuad@xuad.com } notification_email_from root@xuad.com smtp_server mail.xuad.com smtp_connect_timeout 30 router_id LVS_DEVEL vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0}vrrp_script chk_nginx { script &quot;/etc/keepalived/nginx_pid.sh&quot; # 检查nginx状态的脚本 interval 2 weight 3}vrrp_instance VI_1 { state MASTER #备份服务器上将MASTER改为BACKUP interface eth0 virtual_router_id 51 priority 101 #备份服务上将100改为小于100，可配置成90 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 172.17.0.99 #有多个vip可在下面继续增加 } track_script { chk_nginx }} 备份节点 123456789101112131415161718192021222324252627282930313233343536373839! Configuration File for keepalivedglobal_defs { notification_email { xuad@xuad.com } notification_email_from root@xuad.com smtp_server mail.xuad.com smtp_connect_timeout 30 router_id LVS_DEVEL vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0}vrrp_script chk_nginx { script &quot;/etc/keepalived/nginx_pid.sh&quot; # 检查nginx状态的脚本 interval 2 weight 3}vrrp_instance VI_1 { state BACKUP #备份服务器上将MASTER改为BACKUP interface eth0 virtual_router_id 51 priority 99 #备份服务上将100改为小于100，可配置成90 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 172.17.0.99 #有多个vip可在下面继续增加 } track_script { chk_nginx }} nginx_pid.sh 1234567891011#检测nginx是否存活的脚本A=`ps -ef | grep nginx | grep -v grep | wc -l`if [ $A -eq 0 ];then nginx sleep 2 if [ `ps -ef | grep nginx | grep -v grep | wc -l` -eq 0 ];then #killall keepalived ps -ef|grep keepalived|grep -v grep|awk '{print $2}'|xargs kill -9 fifi 修改 nginx 显示的页面，我就修改了这一行，标示是主机还是备份机 主节点 12&lt;strong&gt;nginx master Node&lt;/strong&gt; HTTP server after it has been 从节点 1&lt;strong&gt;nginx Slave Node&lt;/strong&gt; HTTP server after it has been 然后在主机运行curl 172.17.0.99显示 1234... &lt;strong&gt;nginx master Node&lt;/strong&gt; HTTP server after it has been... 关闭主节点后然后在主机运行curl 172.17.0.99显示 123... &lt;strong&gt;nginx slave Node&lt;/strong&gt; HTTP server after it has been... 遇到一个问题没有解决 在主节点运行nginx -s stop 推出 nginx 后，没有切换到从节点，必须关闭主节点。 更新：这个问题看了下是 nginx 检测脚本的问题修改为 123456#!/bin/bash# 如果进程中没有nginx则将keepalived进程kill掉A=`ps -C nginx --no-header |wc -l` ## 查看是否有 nginx进程 把值赋给变量Aif [ $A -eq 0 ];then ## 如果没有进程值得为 零 systemctl stop keepalived.service ## 则结束 keepalived 进程fi 成功了","link":"/2020/06/12/keepalive-docker-nginx%E5%AE%9E%E8%B7%B5/"},{"title":"","text":"规划 IP 地址 主机名 角色 说明 192.168.1.39 k8s-master-lb, k8s-master-lb.jz-sz.com 负载均衡 虚拟IP 192.168.1.40 k8s-master01, k8s-master01.jz-sz.com master master 节点 192.168.1.41 k8s-master02, k8s-master02.jz-sz.com master master 节点 192.168.1.42 k8s-master03, k8s-master03.jz-sz.com master master 节点 192.168.1.46 k8s-node01, k8s-node01.jz-sz.com node node 节点 192.168.1.47 k8s-node02, k8s-node02.jz-sz.com node node 节点 192.168.1.48 k8s-node03, k8s-node03.jz-sz.com node node 节点 192.168.1.49 k8s-node04, k8s-node04.jz-sz.com node node 节点 调整系统参数12345678910111213141516171819202122232425262728cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOFnet.ipv4.ip_forward = 1net.bridge.bridge-nf-call-iptables = 1fs.may_detach_mounts = 1vm.overcommit_memory = 1vm.panic_on_oom = 0fs.inotify.max_user_watches = 89100fs.file-max=52706963fs.nr_open = 52706963net.netfilter.nf_conntrack_max=2310720net.ipv4.tcp_keepalive_time = 600net.ipv4.tcp_keepalive_probes = 3net.ipv4.tcp_keepalive_intvl = 15net.ipv4.tcp_max_tw_buckets = 36000net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_max_orphans = 327680net.ipv4.tcp_orphans_retries = 3net.ipv4.tcp_syncookies = 1net.ipv4.tcp_max_syn_backlog = 16384net.ipv4.tcp_conntrack_max = 65536net.ipv4.tcp_max_syn_backlog = 16384net.ipv4.tcp_timestamps = 0net.core.somaxconn = 16384EOF# 立即生效sysctl --system 安装docker1234567891011121314151617181920212223yum install -y yum-utilsyum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoyum makecache fastyum list docker-ce --showduplicatesyum install -y docker-ce-18.09.9-3.el7 docker-ce-cli-18.09.9-3.el7systemctl enable --now dockercat &gt; /etc/docker/daemon.json &lt;&lt;EOF{ &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;], &quot;insecure-registries&quot;: [&quot;192.168.1.138:5000&quot;], &quot;registry-mirrors&quot;: [ &quot;https://3laho3y3.mirror.aliyuncs.com&quot; ], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: { &quot;max-size&quot;: &quot;100m&quot; }, &quot;storage-driver&quot;: &quot;overlay2&quot;}EOFsystemctl restart docker# 测试docker run hello-world 安装基础组件1234567891011121314vim /etc/yum.repos.d/kubernetes.repocat &lt;&lt; 'EOF' &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enable=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOFyum list kubeadm --showduplicates 版本太新，阿里云镜像不支持12yum install -y kubelet-1.16.6-0 kubeadm-1.16.6-0 kubectl-1.16.6-0systemctl enable --now kubelet 检查初始化需要的镜像12345678kubeadm config images listk8s.gcr.io/kube-apiserver:v1.16.6k8s.gcr.io/kube-controller-manager:v1.16.6k8s.gcr.io/kube-scheduler:v1.16.6k8s.gcr.io/kube-proxy:v1.16.6k8s.gcr.io/pause:3.1k8s.gcr.io/etcd:3.3.15-0k8s.gcr.io/coredns:1.6.2 使用阿里云并标记12345678910111213141516171819202122docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/{镜像名称}:{版本}docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/{镜像名称}:{版本} k8s.gcr.io/{镜像名称}:{版本}docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.16.6docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.16.6docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.16.6docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.16.6docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.3.15-0docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.6.2docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.16.6 k8s.gcr.io/kube-apiserver:v1.16.6docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.16.6 k8s.gcr.io/kube-controller-manager:v1.16.6docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.16.6 k8s.gcr.io/kube-scheduler:v1.16.6docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.16.6 k8s.gcr.io/kube-proxy:v1.16.6docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 k8s.gcr.io/pause:3.1docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.3.15-0 k8s.gcr.io/etcd:3.3.15-0docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.6.2 k8s.gcr.io/coredns:1.6.2docker pull quay.mirrors.ustc.edu.cn/coreos/flannel:v0.12.0-amd64docker tag quay.mirrors.ustc.edu.cn/coreos/flannel:v0.12.0-amd64 quay.io/coreos/flannel:v0.12.0-amd64 初始化 master12345678910111213141516171819202122# 添加地址，方便后续高可用，阿里云或其它云请直接使用slbip addr add 192.168.122.200/32 dev eth0# 可选，生成初始化yamlkubeadm config print init-defaults &gt; init-defaults.yamlkubeadm init --kubernetes-version=1.16.6 \\--pod-network-cidr 10.244.0.0/16 \\--service-cidr 172.21.0.0/20 \\--apiserver-advertise-address=0.0.0.0 \\--control-plane-endpoint &quot;192.168.122.200:6443&quot; \\--upload-certs \\--ignore-preflight-errors=swap# 失败重置kubeadm resetrm -rf $HOME/.kube/config# 普通用户使用 kubectl mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config# 也可以使用环境变量scp k8s-master:/etc/kubernetes/admin.conf /etc/kubernetes/echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; &gt;&gt; ~/.bash_profilesource .bash_profile 配置网络，使用flannel12345678910111213# wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.ymlwget https://github.com/coreos/flannel/blob/master/Documentation/kube-flannel.yml# 替换为对应网段net-conf.json: | { &quot;Network&quot;: &quot;10.244.0.0/16&quot;, &quot;Backend&quot;: { &quot;Type&quot;: &quot;vxlan&quot; } }docker pull quay.mirrors.ustc.edu.cn/coreos/flannel:v0.12.0-amd64docker tag quay.mirrors.ustc.edu.cn/coreos/flannel:v0.12.0-amd64 quay.io/coreos/flannel:v0.12.0-amd64kubectl apply -f kube-flannel.yml 查看集群状态123kubectl get nodes# 检查集群配置kubectl -n kube-system get cm kubeadm-config -o yaml node 拉取镜像123456789101112docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.16.6docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.6.2docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.16.6 k8s.gcr.io/kube-proxy:v1.16.6docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 k8s.gcr.io/pause:3.1docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.6.2 k8s.gcr.io/coredns:1.6.2docker pull quay.mirrors.ustc.edu.cn/coreos/flannel:v0.12.0-amd64docker tag quay.mirrors.ustc.edu.cn/coreos/flannel:v0.12.0-amd64 quay.io/coreos/flannel:v0.12.0-amd64 加入集群1234567891011121314# 添加 masterkubeadm init phase upload-certs --upload-certskubeadm token create --print-join-command# 合并kubeadm join 192.168.122.252:6443 --token qmihb0.2j6ikktkew8ch3vz --discovery-token-ca-cert-hash sha256:db586028c918052bfb1b657472a4bee3d114de93b809b5ff8b53b3b7bded665a \\--control-plane --certificate-key 0b84889916022953e6777da8babe9b643131d104a1d7f91db1a6ae7ddc60d18b# 添加 nodekubeadm token create --print-join-commandkubeadm join 192.168.122.252:6443 --token uopfdg.haazo24wvd8qxxxd \\ --discovery-token-ca-cert-hash sha256:db586028c918052bfb1b657472a4bee3d114de93b809b5ff8b53b3b7bded665a# 删除节点kubectl drain NODE_ID --delete-local-data --force --ignore-daemonsetskubectl delete node NODE_IDkubeadm reset 1234567# 查看集群版本信息kubectl version --short=truekubectl cluster-info# 查看所有pod 状态kubectl get pods --namespace=kube-system# 查看 pod 状态kubectl describe pod kub-proxy-t64ab --namespace=kube-system 安装 helm123helm versiondocker pull registry.cn-hangzhou.aliyuncs.com/kubernetes-helm/tiller:1.6.2docker tag quay.mirrors.ustc.edu.cn/coreos/flannel:v0.12.0-amd64 quay.io/coreos/flannel:v0.12.0-amd64 遇到问题12345678docker pull quay.mirrors.ustc.edu.cn quay 镜像错误：net/http: TLS handshake timeout ，将https://quay.mirrors.ustc.edu.cn&quot; 加入/etc/docker/daemon.json register-mirrorscgdriver 不一致导致不能启动问题cat /etc/docker/daemon.jsoncat /etc/sysconfig/kubeletKUBELET_EXTRA_ARGS=--cgroup-driver=systemd重启 podkubectl get pod {podname} -n {namespace} -o yaml | kubectl replace --force -f -kubectl delete pod -n {namespace} {podname}s","link":"/2020/12/04/kubernetes%20kubeadm%20%E5%AE%89%E8%A3%85/"},{"title":"mybatis拦截器实现日志","text":"直接贴代码关于事务还没测试，等以后再更新 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126package com.gvt.i18n.config;import lombok.extern.slf4j.Slf4j;import org.apache.ibatis.cache.CacheKey;import org.apache.ibatis.executor.Executor;import org.apache.ibatis.mapping.BoundSql;import org.apache.ibatis.mapping.MappedStatement;import org.apache.ibatis.mapping.ParameterMapping;import org.apache.ibatis.mapping.ParameterMode;import org.apache.ibatis.plugin.*;import org.apache.ibatis.reflection.MetaObject;import org.apache.ibatis.session.Configuration;import org.apache.ibatis.session.ResultHandler;import org.apache.ibatis.session.RowBounds;import org.apache.ibatis.type.TypeHandlerRegistry;import java.text.DateFormat;import java.text.SimpleDateFormat;import java.util.Date;import java.util.List;import java.util.Properties;import java.util.regex.Matcher;/** * @author chaoli * @date 2020-06-22 09:36 * @Description **/@Slf4j@Intercepts({ @Signature(type = Executor.class, method = &quot;query&quot;, args = {MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class}), @Signature(type = Executor.class, method = &quot;query&quot;, args = {MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class, CacheKey.class, BoundSql.class}), @Signature(type = Executor.class, method = &quot;update&quot;, args = {MappedStatement.class, Object.class})// @Signature(type = StatementHandler.class, method = &quot;prepare&quot;, args = {Connection.class, Integer.class}),// @Signature(type = ParameterHandler.class, method = &quot;setParameters&quot;, args = {PreparedStatement.class}),// @Signature(type = ResultSetHandler.class, method = &quot;handleResultSets&quot;, args = {Statement.class})})public class ExamplePlugin implements Interceptor { private long time; private static final DateFormat DATE_FORMAT = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); @Override public Object intercept(Invocation invocation) throws Throwable { MappedStatement mappedStatement = (MappedStatement) invocation.getArgs()[0]; Object parameterObject = null; if (invocation.getArgs().length &gt; 1) { parameterObject = invocation.getArgs()[1]; } long start = System.currentTimeMillis(); Object result = invocation.proceed(); String statementId = mappedStatement.getId(); BoundSql boundSql = mappedStatement.getBoundSql(parameterObject); Configuration configuration = mappedStatement.getConfiguration(); String sql = getSql(boundSql, parameterObject, configuration); long end = System.currentTimeMillis(); long timing = end - start; if (log.isInfoEnabled() &amp;&amp; timing &gt; 1) { log.info(&quot;执行sql耗时:&quot; + timing + &quot; ms&quot; + &quot; - id:&quot; + statementId + &quot; - Sql:&quot;); log.info(&quot; &quot; + sql); } // todo: 纪录数据库 return result; } @Override public Object plugin(Object o) { return Plugin.wrap(o, this); } @Override public void setProperties(Properties properties) { } private String getSql(BoundSql boundSql, Object parameterObject, Configuration configuration) { String sql = boundSql.getSql().replaceAll(&quot;[\\\\s]+&quot;, &quot; &quot;); List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings(); TypeHandlerRegistry typeHandlerRegistry = configuration.getTypeHandlerRegistry(); if (parameterMappings != null) { for (int i = 0; i &lt; parameterMappings.size(); i++) { ParameterMapping parameterMapping = parameterMappings.get(i); if (parameterMapping.getMode() != ParameterMode.OUT) { Object value; String propertyName = parameterMapping.getProperty(); if (boundSql.hasAdditionalParameter(propertyName)) { value = boundSql.getAdditionalParameter(propertyName); } else if (parameterObject == null) { value = null; } else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) { value = parameterObject; } else { MetaObject metaObject = configuration.newMetaObject(parameterObject); value = metaObject.getValue(propertyName); } sql = replacePlaceholder(sql, value); } } } return sql; } private String replacePlaceholder(String sql, Object propertyValue) { String result; if (propertyValue != null) { if (propertyValue instanceof String) { result = &quot;'&quot; + propertyValue + &quot;'&quot;; } else if (propertyValue instanceof Date) { result = &quot;'&quot; + DATE_FORMAT.format(propertyValue) + &quot;'&quot;; } else { result = propertyValue.toString(); } } else { result = &quot;null&quot;; } return sql.replaceFirst(&quot;\\\\?&quot;, Matcher.quoteReplacement(result)); }} 123456789101112131415@Configurationpublic class MybatisConfiguration { @Bean public ExamplePlugin myPlugin() { ExamplePlugin myPlugin = new ExamplePlugin(); //设置参数，比如阈值等，可以在配置文件中配置，这里直接写死便于测试 Properties properties = new Properties(); myPlugin.setProperties(properties); return myPlugin; }}","link":"/2020/06/22/mybatis%E6%8B%A6%E6%88%AA%E5%99%A8%E5%AE%9E%E7%8E%B0%E6%97%A5%E5%BF%97/"},{"title":"redis_bitmap翻车的记录.md","text":"今天做一个需求，广告页，要求一天仅显示一次。 数据是存在redis的，当时想着用bitmap可以节约空间，一个用户仅需要 1 bit。但是实际使用中，遇到了几个坑。userId是long型的。bitmap只能用int。 这里把long hash成 int，能解决，但是有hash碰撞的风险。不过就算发生了hash碰撞也无所谓， 然后按这个方案继续。能成功，一切正常。 但是无意中去redis看的时候，这个key 的 大小有 100M。只存一个用户也是100M。然后我还是按不同的商户存不同的bitmap。还好是在测试环境发现了，如果上了生产，就可以直接找工作了。。。 这里分析一下。 bitmap缺失可以节约空间，一个用户最多是256M,一亿个用户也是256M。 但是我们用户少啊。。用这个方案就不太合适了 然后 我们的用户Id是雪花算法Id，不是连续的，其实用bitmap也不适合","link":"/2020/09/16/redis-bitmap%E7%BF%BB%E8%BD%A6%E7%9A%84%E8%AE%B0%E5%BD%95/"},{"title":"一致性哈希","text":"背景这块就简单说一下，一致性哈希是为了解决简单哈希带来的问题。 以 redis 分布式缓存场景为例有大概一百万张图片要分在 4 台机器上，后来数据量变多了，需要增加一台机器。 简单哈希简单哈希的做法是，首先计算哈希值，然后进行取模运算hash(图片名称) % N那么每张图片都会对应到一台机器上，很好的解决了图片分散存储的问题。 但是，当我们需要增加一台服务器的时候就出问题了。 取模运算的结果不一样了，在对应的机器上找不到缓存，大量缓存在同一时间失效，造成了缓存的雪崩 为了解决这个问题，发明了一致性哈希算法。 一致性哈希一致性哈希也是取模算法，但是不是对服务器数量，而是对 2^32 取模。为什么是 2^32?因为，java 中 int 的最大值是 2^31-1 最小值是-2^31,2^32 刚好是无符号整形的最大值； 简单来说，一致性 Hash 算法将整个哈希值空间组织成一个虚拟的圆环，假设某哈希函数 H 的值空间为 0 ～ 2^32-1（即哈希值是一个 32 位无符号整形）哈希算法合理的话，图片应该是大致均匀分布在这个虚拟的圆环上。hash(图片名称) % 2^32 同时服务器也需要进行哈希hash（服务器A的IP地址） % 2^32 图片和服务器都哈希取模完后，就能确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器 假设此时有 C 服务器发生故障，那么原 B~C 的数据会重新定位到 D 服务器，其他服务器的数据则不受影响。增加一台一起也是一样，只有一部分内容会受到影响。具有较好的容错性和可扩展性。 一致性哈希的其他问题及解决方案数据倾斜问题数据倾斜问题指的是，当服务器进行哈希取模的时候，没有平均分配到数据环上。比如 ABCD 全都在右半区，那么 A 节点受到的压力会是最大的，其他节点受到的压力会小一些。解决方案是 增加虚拟节点：即 对每一个节点计算多个哈希值。在实际应用中，通常将虚拟节点数设置为 32 甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。 怎么计算出多个节点Hash(192.168.1.1#1”); // cache A1Hash(192.168.1.1#2”); // cache A2","link":"/2019/11/14/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C/"},{"title":"多路复用IO.md","text":"多路复用的一些参考文章 参考文章： select 用法&amp;原理详解（源码剖析）https://blog.csdn.net/zhougb3/article/details/79792089 深入 select 多路复用内核源码加驱动实现https://my.oschina.net/fileoptions/blog/911091 彻底搞懂 epoll 高效运行的原理https://blog.csdn.net/y277an/article/details/97622206 记录select 是通过 bitmap 来记录所有文件描述符的，所以有最大 1024 个的限制。1024 是内核默认的定义，如果想突破，需要重新编译。 进化路线select ：缺点： 1024 的最大值上限。 每次都需要重新构建 fdset 两次用户态和内核态的拷贝， 需要遍历整个 fdset poll：使用自定义数据结构解决了 select 1024 上限的问题但是还是有其他的缺点 epoll：epoll 底层使用红黑树和链表epoll 会在内核的内存空间开辟一个存储区，通过 epoll_ctl 设置需要监听的文件描述符。当有 socket 就绪后，会通过回调函数，把文件描述符存储到就绪队列中。当用户态程序调用 epoll_wait 时，返回就绪队列。解决了 select 的其他缺点。","link":"/2021/01/24/%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8IO-md/"},{"title":"搭建docker_registry","text":"https://www.cnblogs.com/gcgc/p/10489385.html docker pull registry docker run -d -v /opt/registry:/var/lib/registry -p 5000:5000 –restart=always –name registry registry:latest {“registry-mirrors”: [ “https://pee6w651.mirror.aliyuncs.com&quot;],&quot;insecure-registries&quot;: [“192.168.179.128:5000”]}","link":"/2020/06/12/%E6%90%AD%E5%BB%BAdocker-registry/"},{"title":"搭建elasticsearch_kibana","text":"docker network create elkdocker run -d –name elasticsearch –net elk -p 9200:9200 -p 9300:9300 -e “discovery.type=single-node” elasticsearch:6.5.4docker run -d –name kibana –net elk -p 5601:5601 kibana:6.5.4","link":"/2020/06/13/%E6%90%AD%E5%BB%BAelasticsearch-kibana/"},{"title":"树莓派3搭建linux服务器","text":"前段时间租了三个月阿里云，感觉太贵了，就买了个树莓派 3，准备搭建一个 linux 操作系统，当服务器用用，大概花费不到 300。电源 5V×2.5A，一般情况下不用这么高的电流，功耗其实很低的。 组装就不说了。。成品如下几个要下载的东西:链接：http://pan.baidu.com/s/1o8FC0xO 密码：psww这个是系统把他解压出来是一个.img 文件。 这个软件安装一下。Win32DiskImager-0.9.5-install.exe内存卡，读卡器准备好 然后就写到系统里面 写完以后就可以插到树莓派上了，网线端接路由器的 LAN 口，电脑和树莓派在同一个局域网下。上电，等开好机 在路由器管理页面下可以找到我的是 192.168.0.104 然后就可以用 xshell 连接了然后就登录成功了我这里是用有线连接的，无线的没有去做了OK,大功告成，然后可以开始装各种软件的开发环境了。","link":"/2019/10/24/%E6%A0%91%E8%8E%93%E6%B4%BE3%E6%90%AD%E5%BB%BAlinux%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"title":"注解实现字段自动解密","text":"最近有个项目要传输密码，密码当然不能明文传输。需要前端加密，后端解密。加密算法使用 RSA。 使用注解加 AOP 实现 RSA 工具类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249import javax.crypto.Cipher;import java.security.*;import java.security.spec.InvalidKeySpecException;import java.security.spec.PKCS8EncodedKeySpec;import java.security.spec.X509EncodedKeySpec;import java.util.Arrays;import java.util.Base64;/** * @author chaoli * @date 2020-07-09 10:45 * @Description **/public class RSAUtil { //非对称密钥算法 private static final String KEY_ALGORITHM = &quot;RSA&quot;; //密钥长度，在512到65536位之间，建议不要太长，否则速度很慢，生成的加密数据很长 private static final int KEY_SIZE = 512; //字符编码 private static final String CHARSET = &quot;UTF-8&quot;; /** * 生成密钥对 * * @return KeyPair 密钥对 */ public static KeyPair getKeyPair() throws Exception { return getKeyPair(null); } /** * 生成密钥对 * @param password 生成密钥对的密码 * @return * @throws Exception */ public static KeyPair getKeyPair(String password) throws Exception { //实例化密钥生成器 KeyPairGenerator keyPairGenerator = KeyPairGenerator.getInstance(KEY_ALGORITHM); //初始化密钥生成器 if(password == null){ keyPairGenerator.initialize(KEY_SIZE); }else { SecureRandom secureRandom = SecureRandom.getInstance(&quot;SHA1PRNG&quot;); secureRandom.setSeed(password.getBytes(CHARSET)); keyPairGenerator.initialize(KEY_SIZE, secureRandom); } //生成密钥对 return keyPairGenerator.generateKeyPair(); } /** * 取得私钥 * * @param keyPair 密钥对 * @return byte[] 私钥 */ public static byte[] getPrivateKeyBytes(KeyPair keyPair) { return keyPair.getPrivate().getEncoded(); } /** * 取得Base64编码的私钥 * * @param keyPair 密钥对 * @return String Base64编码的私钥 */ public static String getPrivateKey(KeyPair keyPair) { return Base64.getEncoder().encodeToString(getPrivateKeyBytes(keyPair)); } /** * 取得公钥 * * @param keyPair 密钥对 * @return byte[] 公钥 */ public static byte[] getPublicKeyBytes(KeyPair keyPair) { return keyPair.getPublic().getEncoded(); } /** * 取得Base64编码的公钥 * * @param keyPair 密钥对 * @return String Base64编码的公钥 */ public static String getPublicKey(KeyPair keyPair) { return Base64.getEncoder().encodeToString(getPublicKeyBytes(keyPair)); } /** * 私钥加密 * * @param data 待加密数据 * @param privateKey 私钥字节数组 * @return byte[] 加密数据 */ public static byte[] encryptByPrivateKey(byte[] data, byte[] privateKey) throws Exception { //实例化密钥工厂 KeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM); //生成私钥 PrivateKey key = keyFactory.generatePrivate(new PKCS8EncodedKeySpec(privateKey)); //数据加密 Cipher cipher = Cipher.getInstance(KEY_ALGORITHM); cipher.init(Cipher.ENCRYPT_MODE, key); return cipher.doFinal(data); } /** * 私钥加密 * * @param data 待加密数据 * @param privateKey Base64编码的私钥 * @return String Base64编码的加密数据 */ public static String encryptByPrivateKey(String data, String privateKey) throws Exception { byte[] key = Base64.getDecoder().decode(privateKey); return Base64.getEncoder().encodeToString(encryptByPrivateKey(data.getBytes(CHARSET), key)); } /** * 公钥加密 * * @param data 待加密数据 * @param publicKey 公钥字节数组 * @return byte[] 加密数据 */ public static byte[] encryptByPublicKey(byte[] data, byte[] publicKey) throws Exception { //实例化密钥工厂 KeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM); //生成公钥 PublicKey key = keyFactory.generatePublic(new X509EncodedKeySpec(publicKey)); //数据加密 Cipher cipher = Cipher.getInstance(KEY_ALGORITHM); cipher.init(Cipher.ENCRYPT_MODE, key); return cipher.doFinal(data); } /** * 公钥加密 * * @param data 待加密数据 * @param publicKey Base64编码的公钥 * @return String Base64编码的加密数据 */ public static String encryptByPublicKey(String data, String publicKey) throws Exception { byte[] key = Base64.getDecoder().decode(publicKey); return Base64.getEncoder().encodeToString(encryptByPublicKey(data.getBytes(CHARSET), key)); } /** * 私钥解密 * * @param data 待解密数据 * @param privateKey 私钥字节数组 * @return byte[] 解密数据 */ public static byte[] decryptByPrivateKey(byte[] data, byte[] privateKey) throws Exception { //实例化密钥工厂 KeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM); //生成私钥 PrivateKey key = keyFactory.generatePrivate(new PKCS8EncodedKeySpec(privateKey)); //数据解密 Cipher cipher = Cipher.getInstance(KEY_ALGORITHM); cipher.init(Cipher.DECRYPT_MODE, key); return cipher.doFinal(data); } /** * 私钥解密 * * @param data Base64编码的待解密数据 * @param privateKey Base64编码的私钥 * @return String 解密数据 */ public static String decryptByPrivateKey(String data, String privateKey) throws Exception { byte[] key = Base64.getDecoder().decode(privateKey); return new String(decryptByPrivateKey(Base64.getDecoder().decode(data), key), CHARSET); } /** * 公钥解密 * * @param data 待解密数据 * @param publicKey 公钥字节数组 * @return byte[] 解密数据 */ public static byte[] decryptByPublicKey(byte[] data, byte[] publicKey) throws Exception { //实例化密钥工厂 KeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM); //产生公钥 PublicKey key = keyFactory.generatePublic(new X509EncodedKeySpec(publicKey)); //数据解密 Cipher cipher = Cipher.getInstance(KEY_ALGORITHM); cipher.init(Cipher.DECRYPT_MODE, key); return cipher.doFinal(data); } /** * 公钥解密 * * @param data Base64编码的待解密数据 * @param publicKey Base64编码的公钥 * @return String 解密数据 */ public static String decryptByPublicKey(String data, String publicKey) throws Exception { byte[] key = Base64.getDecoder().decode(publicKey); return new String(decryptByPublicKey(Base64.getDecoder().decode(data), key), CHARSET); } /** * 测试加解密方法 * * @param args * @throws Exception */ public static void main(String[] args) throws Exception { //生成密钥对，一般生成之后可以放到配置文件中 KeyPair keyPair = RSAUtil.getKeyPair(); //公钥 String publicKey = RSAUtil.getPublicKey(keyPair); //私钥 String privateKey = RSAUtil.getPrivateKey(keyPair); System.out.println(&quot;公钥：\\n&quot; + publicKey); System.out.println(&quot;私钥：\\n&quot; + privateKey); String data = &quot;123321&quot;; { System.out.println(&quot;\\n===========私钥加密，公钥解密==============&quot;); String s1 = RSAUtil.encryptByPrivateKey(data, privateKey); System.out.println(&quot;加密后的数据:&quot; + s1); String s2 = RSAUtil.decryptByPublicKey(s1, publicKey); System.out.println(&quot;解密后的数据:&quot; + s2 + &quot;\\n\\n&quot;); } { System.out.println(&quot;\\n===========公钥加密，私钥解密==============&quot;); String s1 = RSAUtil.encryptByPublicKey(data, publicKey); System.out.println(&quot;加密后的数据:&quot; + s1); String s2 = RSAUtil.decryptByPrivateKey(s1, privateKey); System.out.println(&quot;解密后的数据:&quot; + s2 + &quot;\\n\\n&quot;); } }} 字段注解 123456@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface RSAField {} 方法注解 12345@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)//声明此注解生命周期 使用runtime可以在运行时动态获得注解信息@Documentedpublic @interface RSAMethod {} AOP 实现。代理所有加了 RSAMethod 注解的方法，遍历所有参数对象的字段，如果字段有 RSAField 注解， 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667@Component@Aspect@Slf4jpublic class EncryptDecryptAop { @Value(&quot;${privateKey}&quot;) private String privateKey; @Pointcut(&quot;@annotation(xx.xx.xx.xx.RSAMethod)&quot;) public void annotationPointCut() { } @Around(&quot;annotationPointCut()&quot;) public Object doProcess(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { //捕获方法参数列表 List&lt;Object&gt; methodArgs = this.getMethodArgs(proceedingJoinPoint); //循环所有参数 for (Object item : methodArgs) { //捕获参数类中的所有字段 Field[] fields = item.getClass().getDeclaredFields(); //遍历所有字段 for (Field field : fields) { //若该字段被EncryptField注解,则进行加密 if (null != AnnotationUtils.findAnnotation(field, RSAField.class)) { String raw = null; try { //设置private类型允许访问 field.setAccessible(Boolean.TRUE); raw = field.get(item).toString(); } catch (Exception e) { continue; } if (raw == null || raw.isEmpty()) { continue; }// log.info(&quot;{}解密前{}&quot;, field.getName(), raw); String decrypt = null; try { //解密 decrypt = RSAUtil.decryptByPrivateKey(raw, privateKey); } catch (Exception e) { log.warn(&quot;RAS解密失败{}&quot;, field.getName()); // throw new ServiceException(ErrorEnums.PARAM_ERROR.getCode(), &quot;加密解密失败&quot;); } field.set(item, decrypt);// log.info(&quot;{}解密后{}&quot;, field.getName(), field.get(item).toString()); field.setAccessible(Boolean.FALSE); } } } return proceedingJoinPoint.proceed(); } /** * 获取方法请求参数 */ private List&lt;Object&gt; getMethodArgs(ProceedingJoinPoint proceedingJoinPoint) { List&lt;Object&gt; methodArgs = Lists.newArrayList(); for (Object arg : proceedingJoinPoint.getArgs()) { if (null != arg) { methodArgs.add(arg); } } return methodArgs; }}","link":"/2020/07/10/%E6%B3%A8%E8%A7%A3%E5%AE%9E%E7%8E%B0%E5%AD%97%E6%AE%B5%E8%87%AA%E5%8A%A8%E8%A7%A3%E5%AF%86/"},{"title":"编译安装Nginx","text":"https://blog.csdn.net/dmedaa/article/details/89885889 ./configure –prefix=/usr/local/nginx –with-http_stub_status_module http://blog.oneapm.com/apm-tech/412.html nginx status 详解active connections – 活跃的连接数量server accepts handled requests — 总共处理了 11989 个连接 , 成功创建 11989 次握手, 总共处理了 11991 个请求reading — 读取客户端的连接数.writing — 响应数据到客户端的数量waiting — 开启 keep-alive 的情况下,这个值等于 active – (reading+writing), 意思就是 Nginx 已经处理完正在等候下一次请求指令的驻留连接.","link":"/2020/06/12/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85Nginx/"},{"title":"记录一次线上宕机的问题2020_02_20.md","text":"今天一个核心系统宕机了，导致所有服务不可用，在自动重启后又恢复了。 下面记录整个排查过程 我们使用的环境是 dockerJDK 版本 1.8参数是 123JVM_OPTIONS=&quot;-Xms2048M -Xmx2048M -Xss512K -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=68 -XX:ParallelGCThreads=4 -XX:+CMSClassUnloadingEnabled -Xloggc:logs/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCDetails&quot;LIMIT_MEMORY=2.5GSERVICE_REPLICAS=4 新生代老年代默认比例是 1:2最大内存是 2G老年代是 1365M 通过 JProfiler 分析 dump 文件 发现有一个大对象，600 多 M 查看对象引用 发现对象是来自于 MemoryCacheStore 这个类，然后可以定位到代码。 代码发现 1234567891011121314151617// 自定义缓存管理器private static final SecurityMemoryCacheManager cacheManager = new SecurityMemoryCacheManager();-------private static class SecurityMemoryCacheManager extends SimpleCacheManager { @Override protected Cache getMissingCache(String name) { return new ConcurrentMapCache(CACHE_NAME_PREFIX + name); }}-------public ConcurrentMapCache(String name) { this(name, new ConcurrentHashMap&lt;&gt;(256), true);} 代码确实发现了一个 ConcurrentHashMap 进一步分析业务逻辑，发现这个 map 是第一个架构师写的用于存储 token 和权限的。实际上已经没有用到了，但是陈年老代码，也没有删除。 为什么会在这个时间出现也分析了一下原因。以前这个系统经常有功能要上线，一般一个星期就会发版重启一次，但是年前那段时间，没有新功能，也就没有发版，又过了一个年，导致内存占用越来越多。直到 OOM。索性系统会自动恢复，没有造成巨大影响。","link":"/2021/02/22/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E5%AE%95%E6%9C%BA%E7%9A%84%E9%97%AE%E9%A2%982020-02-20-md/"},{"title":"记录：在K8S上创建高可用的MySql集群","text":"更新 2 查看了 kubernetes 的资料和配置Pod CIDR 10.9.12.0/24Pod CIDR 10.9.13.0/24Pod CIDR 10.10.11.0/24 这里不连续的原因是， Mysql-0 和 Mysql-1 使用的两台机器是常年开着的，没有关闭过而 Mysql-2 使用的机器是刚刚创建的，而我们的集群有个特点，就是频繁的创建和删除节点。 这里猜测 kubernetes 在分配 ip 的时候是顺序分配的,如果分配完了再从头开始分配，把已经释放的重新分配。 由于我们使用的是 Google kubernetes，很多东西是无法更改的。所以解决方案我认为有： 重新创建一个 nodepool,把 mysql 部署在这个新创建的 nodepool 上，这样新的机器大概率 IP 连续。 修改 kubedb 的源码，把白名单的子网掩码修改为/8。其实我觉得这里作者的代码应该优化一下，使用 service 的方式来寻找 pod，而不是通过 Pod IP。 寻找其他 MySql 高可用部署的解决方案 我准备就创建一个 nodepool，因为从我的个人实际情况出发，这是最简单有效，最快速的解决方案，然后问题也和提了 issue，希望作者会进行优化。 更新 1问题查了下，看了下作者的更新记录https://github.com/kubedb/mysql/commit/1db0fa511d31f32bf36b4dcdc07733d3853f3d18关键的几行 1234myips=$(hostname -I)first=${myips%% *}# Now use this IP with CIDR notationexport whitelist=&quot;${first}/16&quot; 然后我确认了下我的 IP：mysql-0: 1IP: 10.9.12.246 mysql-2: 1IP: 10.10.11.2 这里 kubernetes 内网 IP 的第二个数不一样，作者的掩码是/16，我这里需要/8我觉得这个问题应该在 kubernetes 这里找解决方案 原文参考文章：https://jeremy-xu.oschina.io/2019/08/kubernetes%E4%B8%AD%E9%83%A8%E7%BD%B2mysql%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/https://kubedb.com/docs/0.12.0/guides/mysql/clustering/overview/ 按照博主的文章，确实搭建成功了。但是在后续改进的时候遇到了问题，目前还没有解决，先记录下来，以后解决了再修改。 我使用的是 google 的 kubernetes,这里使用的是一台四核的机器，三个节点全部部署在同一台机器上，上面还有一些其他的服务，基本上单节点分配不到一个核。在另一台单核的 VM 上使用 sysbench 进行测试 123sysbench /usr/share/sysbench/oltp_read_write.lua --time=180 --mysql-host=mysqlip --mysql-port=3306 --mysql-user=root --mysql-password=mysqlmima --mysql-db=demo --table-size=50000 --tables=8 --threads=8 preparesysbench /usr/share/sysbench/oltp_read_write.lua --time=180 --mysql-host=mysqlip --mysql-port=3306 --mysql-user=root --mysql-password=mysqlmima --mysql-db=demo --table-size=50000 --tables=8 --threads=8 run &gt;&gt; k8smysql.log 第一次直接挂了，改小数据量后重新测试得到测试报告 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849sysbench 1.0.19 (using bundled LuaJIT 2.1.0-beta2)Running the test with following options:Number of threads: 8Initializing random number generator from current timeInitializing worker threads...Threads started!FATAL: mysql_stmt_execute() returned error 2013 (Lost connection to MySQL server during query) for query 'SELECT c FROM sbtest7 WHERE id=?'FATAL: `thread_run' function failed: /usr/share/sysbench/oltp_common.lua:419: SQL error, errno = 2013, state = 'HY000': Lost connection to MySQL server during querysysbench 1.0.19 (using bundled LuaJIT 2.1.0-beta2)Running the test with following options:Number of threads: 8Initializing random number generator from current timeInitializing worker threads...Threads started!SQL statistics: queries performed: read: 310646 write: 68981 other: 64143 total: 443770 transactions: 22187 (123.19 per sec.) queries: 443770 (2463.94 per sec.) ignored errors: 2 (0.01 per sec.) reconnects: 0 (0.00 per sec.)General statistics: total time: 180.1038s total number of events: 22187Latency (ms): min: 22.81 avg: 64.91 max: 370.94 95th percentile: 139.85 sum: 1440248.80Threads fairness: events (avg/stddev): 2773.3750/1495.23 execution time (avg/stddev): 180.0311/0.04 说实话性能一般，所以准备使用更好的机器继续测试性能，让单个节点使用两个核。 这一步的时候出问题了，集群起不来。查了一下，发现有人也遇到了同样的问题，作者说解决了，但是我今天实测还是出了这个问题。https://github.com/kubedb/project/issues/529目前没有找到很好的解决方案，在 github 上提了新的 issuehttps://github.com/kubedb/project/issues/702希望可以得到解决。","link":"/2019/12/14/%E8%AE%B0%E5%BD%95%EF%BC%9A%E5%9C%A8K8S%E4%B8%8A%E5%88%9B%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84MySql%E9%9B%86%E7%BE%A4/"}],"tags":[{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","link":"/tags/SpringBoot/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"rxjava","slug":"rxjava","link":"/tags/rxjava/"},{"name":"分布式","slug":"分布式","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"哈希","slug":"哈希","link":"/tags/%E5%93%88%E5%B8%8C/"},{"name":"一致性哈希","slug":"一致性哈希","link":"/tags/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"树莓派","slug":"树莓派","link":"/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/"}],"categories":[]}